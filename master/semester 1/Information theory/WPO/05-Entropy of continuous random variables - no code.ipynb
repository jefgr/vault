{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy of continous random variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Entropy of uniform distribution\n",
    "\n",
    "Consider a uniform distributed random variable $X$. Determine \n",
    "1. the variance (=power) and the entropy for a uniform distribution beween 0 and 1.\n",
    "2. the variance and the entropy for a uniform distribution beween -1/2 and +1/2.\n",
    "3. the variance and the entropy for a uniform distribution beween -2 and +2.\n",
    "\n",
    "Note that \n",
    "1. neither the variance nor the entropy change when an offset is applied (cases 1 and 2)\n",
    "2. the variance scales as $a^2$ and the entropy is offsetted by $\\log (|\\det (a)|)$ when scaling the random variable with a factor $a$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Var(X) = 0.08333333333333333, Hx = 0.0\n",
      "2) Var(X) = 0.08333333333333333, Hx = 0.0\n",
      "3) Var(X) = 1.3333333333333333, Hx = 2.0\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "var_1 = (1 - 0) ** 2 / 12\n",
    "h_1 = log2(1 - 0 )\n",
    "\n",
    "var_2 = (1/2 - (-1/2)) ** 2 / 12\n",
    "h_2 = log2(1/2 - (-1/2))\n",
    "\n",
    "var_3 = (2 - (-2)) ** 2 / 12\n",
    "h_3 = log2(2 - (-2) )\n",
    "\n",
    "print(f\"1) Var(X) = {var_1}, Hx = {h_1}\")\n",
    "print(f\"2) Var(X) = {var_2}, Hx = {h_2}\")\n",
    "print(f\"3) Var(X) = {var_3}, Hx = {h_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Entropy of Gaussian distribution\n",
    "\n",
    "Consider a Gaussian distributed random variable $X$. Determine \n",
    "1. the variance (=power) and the entropy for a Gaussian distribution with mean = 1 and variance = 1.\n",
    "2. the variance and the entropy for a Gaussian distribution with zero mean and unity variance.\n",
    "3. the variance and the entropy for a Gaussian distribution with zero mean and variance = 16.\n",
    "\n",
    "Note that \n",
    "1. neither the variance nor the entropy change when an offset is applied (cases 1 and 2)\n",
    "2. the variance scales as $a^2$ and the entropy is offsetted by $\\log (|\\det (a)|)$ when scaling the random variable with a factor $a$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Var(X) = 1, Hx = 2.047095585180641\n",
      "2) Var(X) = 1, Hx = 2.047095585180641\n",
      "3) Var(X) = 16, Hx = 4.047095585180641\n"
     ]
    }
   ],
   "source": [
    "from math import pi, e\n",
    "var_1 = 1\n",
    "h_1 = 0.5 * log2( 2 * pi * e * var_1)\n",
    "\n",
    "var_2 = 1\n",
    "h_2 = 0.5 * log2( 2 * pi * e * var_2)\n",
    "\n",
    "var_3 = 16\n",
    "h_3 = 0.5 * log2( 2 * pi * e * var_3)\n",
    "\n",
    "print(f\"1) Var(X) = {var_1}, Hx = {h_1}\")\n",
    "print(f\"2) Var(X) = {var_2}, Hx = {h_2}\")\n",
    "print(f\"3) Var(X) = {var_3}, Hx = {h_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy of independent Gaussian distributions\n",
    "\n",
    "The entropy of a set of n independent, zero-mean Gaussian distributed random variables $x_{1},\\ldots,x_{n}$ with variances $\\sigma_{x_{1}}^{2},\\ldots,\\sigma_{x_{n}}^{2}$ equals $$ \\sum_{i=1}^{n}[\\frac{1}{2}\\log(2\\pi\\sigma_{x_{i}}^{2})+\\frac{1}{2}\\log(e)]. $$\n",
    "\n",
    "Consider independent Gaussian distributions with a variance of $\\sigma^2 = [1, 2, 4, 9, 3]$.\n",
    "Determine the total entropy of these distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H(x) = 14.112921676984941\n"
     ]
    }
   ],
   "source": [
    "# Fout in orginele formule alles moet in de sommatie\n",
    "vars = [1, 2, 4, 9, 3]\n",
    "\n",
    "Hvars = sum(0.5 * log2(2 * pi * var) for var in vars) + 0.5 * log2(e)\n",
    "Hvars = sum(0.5 * log2(2 * pi * var) + 0.5 * log2(e) for var in vars)\n",
    "\n",
    "print(f\"H(x) = {Hvars}\") # Fout in verbeter sleutel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian distribution maximizes the entropy under fixed power constraint\n",
    "\n",
    "Consider a uniform and a Gaussian with identical variances. Compute the entropy for equal variances and note that the entropy of the Gaussian distribution is the largest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320508075688772\n",
      "Uniform: H(x) = 1.792481250360578\n",
      "Gaussian: H(x) = 2.047095585180641\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "# variance = 1\n",
    "var = 1\n",
    "b_minus_a = sqrt(var * 12)\n",
    "print(b_minus_a/2)\n",
    "h_uniform = log2(b_minus_a)\n",
    "\n",
    "h_gaussian = 0.5 * log2( 2 * pi * e * var)\n",
    "print(f\"Uniform: H(x) = {h_uniform}\")\n",
    "print(f\"Gaussian: H(x) = {h_gaussian}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
