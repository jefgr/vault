{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov processes\n",
    "\n",
    "A Markov process can be used to describe the dependency between consecutive data samples. This is done using the state-transition matrix \n",
    "$$\\boldsymbol{P}=\\left[\\begin{array}{ccc}\n",
    "P_{11} & P_{12} & P_{13}\\\\\n",
    "P_{21} & P_{22} & P_{23}\\\\\n",
    "P_{31} & P_{32} & P_{33}\n",
    "\\end{array}\\right]$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov model for the weather of the Land of Oz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider that the weather in the land of Oz can be one of n=3 states: x_{1}=R: rainy weather, x_{2}=N: nice weather, and x_{3}=S: snowy weather. The state diagram of a stationary Markov process that is characterized by its state-transition matrix \n",
    "$$ \\boldsymbol{P}=\\left[\\begin{array}{ccc}\n",
    "1/2 & 1/4 & 1/4 \\\\\n",
    "1/2 & 0 & 1/2 \\\\\n",
    "1/4 & 1/4 & 1/2\n",
    "\\end{array}\\right] $$ \n",
    "where the elements $i,j$ specify the probability $$ \\boldsymbol{P}_{ij} = P[X(k)=x_{j}(k)|X(k-1)=x_{i}(k-1)] $$ that the next state is $x_{j}$ when you are currently ($k-1$) in state $x_i$.\n",
    "\n",
    "Remark that this matrix contains probabilities on each row (each row corresponding to a different current state $x_i$.) Hence, $$ \\sum_{j=1}^n P_{ij} = 1 \\qquad \\forall i.$$ The matrix is therefore called to be a row stochastic matrix.\n",
    "\n",
    "Define the matrix $\\boldsymbol{P}$ in numpy and show that it is a row stochastic matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a realization of the weather of the land of Oz\n",
    "\n",
    "Generate and print a realization of length 20 of the weather of the land of Oz starting from the initial state: the nice weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability to be in a state\n",
    "\n",
    "To determine the entropy of a Markov source, it is necessary to determine the probability to be in a given state. Using the Markov process generator defined before, generate the a realization a sequence of 100000 state and determine the probability of have rainly, nice and snowy weather. This corresponds with a finite sample estimation of the probability vector $\\boldsymbol{\\pi}$ introduced in the theory.\n",
    "\n",
    "Note that for different realizations, one obtains similar results for the probabilty of being in a certain state (try running this algorthm different times and look to the results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties stochastic matrix\n",
    "\n",
    "It is known that for a row stochastic matrix such as $\\boldsymbol{P}$ that its largest left eigenvalue $\\lambda_{1}=1$. If there is a unique stationary distribution (only the largest eigenvalue equals to one, or mathematically $1=\\lambda_{1}>\\lambda_{2})$, then the largest eigenvalue is unique (=1) and hence, the corresponding eigenvector $(\\boldsymbol{W}_{[1,:]})$ are both unique \n",
    "$$\\boldsymbol{P}=\\boldsymbol{W}^{-1}\\boldsymbol{D}\\boldsymbol{W}$$\n",
    "with $\\boldsymbol{W}$  the matrix of eigenvectors and $\\boldsymbol{D}$ the diagonal matrix of *left* eigenvalues.\n",
    "\n",
    "First, compute the eigenvalues and eigenvectors using the linalg.eig function. As the eig function computes the *right* eigenvalues/eigenvector problem, we have to work on the transposed probability matrix.\n",
    "\n",
    "Verify that exactly one eigenvalue equals 1 and print the eigenvectors (but don't forget the transpose operation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that one eigenvalue is equal to 1 while all others are $|\\lambda_i|<1$ for all $i=2,\\ldots,n$. \n",
    "\n",
    "Check that the eigenvector coresponding to the largest eigenvalue is not representing a probability vectors with  $0 \\le p_i \\le 1$ and $$ \\sum_{i=1}^n p_i = 1 $$ but with a quadratic norm scaling $$ \\sum_{i=1}^n w_i^2 = 1. $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to scale an eigenvector with an arbitrary constant. Determine the scaling of the eigenvector such that it becomes an probability vector, which is mathematically represented by $\\boldsymbol{\\pi}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy of a Markov process\n",
    "\n",
    "The entropy of a (stationary and ergodic) Markov process equals\n",
    "$$ H(X)\t=\t-\\sum_{i=1}^{n}\\sum_{j=1}^{n}\\pi_{i}P_{ij}\\log P_{ij}. $$\n",
    "Determine the entropy of the considered Markov process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covergence to the asymptotic probability\n",
    "\n",
    "The vector $\\boldsymbol{\\pi}$ gives use the probabiltiy $p(x_i)$ that the Markov process is in state $x_i$. The assumption that the Markov process is stationary and ergodic implies that there is only the largest eigenvalue equal is to one. Due to this, the process will always converge to this distribution, irrespective of probability distribution at the initial time of $k=0$.\n",
    "\n",
    "To illustrate this, consider an arbitrary probability distribution, perform 5 successive steps in the Markov process, and compare the final probability vector with the asymptotic one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
