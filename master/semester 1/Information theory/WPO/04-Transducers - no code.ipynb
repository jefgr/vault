{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transducers\n",
    "\n",
    "## Data processing inequality\n",
    "\n",
    " The output Y of a finite state transducer driven by a finite state statistical source (=a stationary and ergodic Markov process) $X$, is a finite state statistical source with information rate (=entropy per unit time) $R(Y)$ that less than or equal to that of the input entropy $R(X)$ $$R(Y)\\le R(X).$$\n",
    " \n",
    " If the transducer is non-singular, then the equality holds $$R(Y) = R(X).$$\n",
    "\n",
    "### Information rate and channel capacity\n",
    "\n",
    " Assume that the transducer generates a binary sample $Y$ every $T_{s}=1ms$. The maximum information rate equals $R_{max}=1/T_s$ bits per sample or equivalently bits per seconds if all these samples are independent and with equal probability for a '0' and a '1'. Hence, the maximal information rate $R_{max}=1/T_s$ bits$. \n",
    "\n",
    " If the transducer is non-signular (= reversable), then the data processing inequality learns us that the channel capacity $$ C= R_{max}(X)=R_{max}(Y)=1/T_s$$  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed code length (=block code)\n",
    "\n",
    "Consider the bineary encoding with the following fixed code length\n",
    "\n",
    "| $i$ | code | $p(x_{i})$ |\n",
    "| --- | --- | --- |\n",
    "| $1$ | $00$ | $0.4$ |\n",
    "| $2$ | $01$ | $0.3$ |\n",
    "| $3$ | $10$ | $0.2$ |\n",
    "| $4$ | $11$ | $0.1$ |\n",
    "\n",
    "Note that this transducer is non-signular.\n",
    "\n",
    "Compute the symbol length, the average symbol length of the binary source, and the information rate expressed in bit/sample (where sample represents a single bit in the binary stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: [2, 2, 2, 2]\n",
      "<N> = 2.0\n",
      "H(X) = 1.8464393446710154 bit\n",
      "R(X) = 0.9232196723355077 bit/sample\n"
     ]
    }
   ],
   "source": [
    "from math import log2\n",
    "i = [1, 2, 3, 4]\n",
    "code = [\"00\", \"01\", \"10\", \"11\"]\n",
    "px = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "N = [len(c) for c in code]\n",
    "avg_N = sum(N) / len(N)\n",
    "print(f\"N: {N}\")\n",
    "print(f\"<N> = {avg_N}\")\n",
    "\n",
    "Hx = - sum(pxi * log2(pxi) for pxi in px)\n",
    "print(f\"H(X) = {Hx} bit\")\n",
    "Rx = Hx / avg_N\n",
    "print(f\"R(X) = {Rx} bit/sample\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the duration of the symbol, the average symbol duration and the information rate expressed in bit/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tau average = 0.002 s/symbol\n",
      "R(X) = 923.2196723355077 bit/s\n"
     ]
    }
   ],
   "source": [
    "ts = 0.001\n",
    "taus = [ts * n for n in N]\n",
    "tau_avg = sum(taus) / len(taus)\n",
    "print(f\"tau average = {tau_avg} s/symbol\")\n",
    "Rxs = Rx / ts\n",
    "print(f\"R(X) = {Rxs} bit/s\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the absolute redundancy $$R_X = C - R(X)$$ the relative redundancy $$r_{X} = 1-\\frac{R(X)}{C}$$ and the efficiency $$e_{X}=\\frac{R(X)}{C}.$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the probability of 0 and 1\n",
    "\n",
    "First consider $N$ symbols (with $N$ tending to infinity, e.g. $N=1000$). For these $N$ symbols, the count the number of zeros and the estimated length. The ratio of the number of zeros and the estimated length is then the propability of encounterint zero. (The propability of a one is 1 minus this probability)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable length code\n",
    "\n",
    "Consider the bineary encoding with the following fixed code length\n",
    "\n",
    "| $i$ | code | $p(x_{i})$ |\n",
    "| --- | --- | --- |\n",
    "| $1$ | $0$ | $0.4$ |\n",
    "| $2$ | $10$ | $0.3$ |\n",
    "| $3$ | $110$ | $0.2$ |\n",
    "| $4$ | $111$ | $0.1$ |\n",
    "\n",
    "This is also a non-signular transducer as this represent a pre-fix code (proof: see later).\n",
    "\n",
    "Compute the symbol length, the average symbol length of the binary source, and the information rate expressed in bit/sample."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the duration of the symbol, the average symbol duration and the information rate expressed in bit/s."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the absolute redundancy, the relative redundancy, and the efficiency."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the probability of 0 and 1\n",
    "\n",
    "First consider $N$ symbols (with $N$ tending to infinity, e.g. $N=1000$). For these $N$ symbols, the count the number of zeros and the estimated length. The ratio of the number of zeros and the estimated length is then the propability of encounterint zero. (The propability of a one is 1 minus this probability)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
